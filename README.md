# Exp√©riences d'Apprentissage F√©d√©r√© et Attaques d'Inf√©rence de Membership

Ce projet impl√©mente diff√©rentes approches d'apprentissage automatique et √©value leur vuln√©rabilit√© aux attaques d'inf√©rence de membership (MIA) sur le dataset CIFAR-10.

## üéØ Objectifs

1. **Comparer diff√©rentes approches d'apprentissage** :
   - Apprentissage centralis√©
   - Mod√®les individuels par client
   - Ensemble de mod√®les
   - Transfert cyclique de poids
   - Apprentissage f√©d√©r√© (FedAvg)

2. **√âvaluer la confidentialit√©** :
   - Attaques d'inf√©rence de membership
   - Attaques d'outsider vs insider
   - M√©triques de confidentialit√©

## üìã Pr√©requis

```bash
pip install tensorflow numpy scikit-learn matplotlib
```

## üöÄ Utilisation Rapide

### Option 1: Script d'ex√©cution automatique
```bash
python run_experiments.py
```

### Option 2: Script principal avec options
```bash
# Exp√©rience compl√®te
python main.py

# Seulement les attaques (mod√®les existants)
python main.py --skip-training

# Seulement l'entra√Ænement
python main.py --skip-attacks

# Avec visualisations
python main.py --visualize
```

## üìÅ Structure du Projet

```
federated_learning_project/
‚îú‚îÄ‚îÄ config.py                    # Configuration et param√®tres
‚îú‚îÄ‚îÄ data_preparation.py          # Pr√©paration des donn√©es CIFAR-10
‚îú‚îÄ‚îÄ models.py                    # D√©finitions des mod√®les
‚îú‚îÄ‚îÄ centralized_training.py      # Entra√Ænement centralis√©
‚îú‚îÄ‚îÄ single_models.py             # Mod√®les individuels
‚îú‚îÄ‚îÄ ensemble_models.py           # Ensembles de mod√®les
‚îú‚îÄ‚îÄ cyclic_weight_transfer.py    # Transfert cyclique de poids
‚îú‚îÄ‚îÄ federated_learning.py        # Apprentissage f√©d√©r√© (FedAvg)
‚îú‚îÄ‚îÄ membership_inference_attack.py # Attaques MIA
‚îú‚îÄ‚îÄ utils.py                     # Utilitaires et visualisations
‚îú‚îÄ‚îÄ main.py                      # Script principal
‚îú‚îÄ‚îÄ run_experiments.py           # Script d'ex√©cution rapide
‚îî‚îÄ‚îÄ README.md                    # Documentation
```

## üî¨ Exp√©riences Impl√©ment√©es

### 1. Approches d'Apprentissage

#### Apprentissage Centralis√©
- Un seul mod√®le entra√Æn√© sur toutes les donn√©es
- R√©f√©rence pour les comparaisons de performance

#### Mod√®les Individuels
- Un mod√®le par client, entra√Æn√© seulement sur ses donn√©es
- Simule la non-collaboration entre clients

#### Ensemble de Mod√®les
- Combinaison des pr√©dictions des mod√®les individuels
- Moyenne des probabilit√©s de sortie

#### Transfert Cyclique de Poids
- Entra√Ænement s√©quentiel sur chaque client
- Transfert des poids entre clients √† chaque tour

#### Apprentissage F√©d√©r√© (FedAvg)
- Algorithme FedAvg standard
- Agr√©gation des gradients locaux

### 2. Attaques d'Inf√©rence de Membership

#### Attaque d'Outsider
- Attaquant externe sans acc√®s aux donn√©es d'entra√Ænement
- Utilise des mod√®les shadow entra√Æn√©s sur des donn√©es publiques

#### Attaque d'Insider
- Attaquant participant (client malveillant)
- Utilise ses propres donn√©es et l'acc√®s au mod√®le

#### Attaque MIA Originale
- Impl√©mentation de l'attaque de Shokri et al.
- Utilise plusieurs mod√®les shadow et mod√®les d'attaque par classe

## üìä M√©triques √âvalu√©es

### Performance des Mod√®les
- Pr√©cision (Accuracy)
- Perte (Loss)
- Comparaison entre approches

### Confidentialit√©
- Pr√©cision des attaques MIA
- Pr√©cision par classe
- Avantage de l'attaque (Attack Advantage)
- Perte de confidentialit√© (Privacy Loss)

## üîß Configuration

### Param√®tres par d√©faut (`config.py`)
```python
CLIENTS = 3              # Nombre de clients
SIZE = 5000             # Taille des donn√©es par client
EPOCHS_CENTRALIZED = 36  # √âpoques pour l'entra√Ænement centralis√©
EPOCHS_FEDERATED = 36   # Tours pour l'apprentissage f√©d√©r√©
BATCH_SIZE = 32         # Taille des lots
```

### Personnalisation
Modifiez `config.py` pour ajuster :
- Nombre de clients
- Taille des datasets
- Param√®tres d'entra√Ænement
- Param√®tres d'attaque

## üìà R√©sultats et Visualisations

### Fichiers g√©n√©r√©s
- `models/`: Mod√®les entra√Æn√©s sauvegard√©s
- `logs/`: Logs d√©taill√©s des exp√©riences
- `visualizations/`: Graphiques et visualisations

### Types de visualisations
- Courbes d'entra√Ænement
- Comparaison des performances
- R√©sultats des attaques par classe
- M√©triques de confidentialit√©

## üõ°Ô∏è Analyse de Confidentialit√©

### Interpr√©tation des R√©sultats
- **Pr√©cision d'attaque > 70%** : Risque √©lev√©
- **Pr√©cision d'attaque 60-70%** : Risque mod√©r√©
- **Pr√©cision d'attaque 55-60%** : Risque faible
- **Pr√©cision d'attaque < 55%** : Risque minimal

### Recommandations
- Utiliser des techniques de pr√©servation de la confidentialit√©
- Differential Privacy
- Agr√©gation s√©curis√©e
- Bruit ajout√© aux gradients

## üîç D√©tails Techniques

### Architecture des Mod√®les
```python
# Mod√®le CNN pour CIFAR-10
Conv2D(32, (5,5)) -> MaxPooling2D -> 
Conv2D(64, (5,5)) -> MaxPooling2D -> 
Flatten -> Dense(512) -> Dense(10)
```

### Algorithme FedAvg
1. Initialiser le mod√®le global
2. Pour chaque tour de communication :
   - Distribuer le mod√®le global aux clients
   - Entra√Ænement local sur chaque client
   - Calculer les deltas de poids
   - Agr√©ger les deltas (moyenne)
   - Mettre √† jour le mod√®le global

### Attaques MIA
1. **Entra√Ænement des mod√®les shadow**
   - Mod√®les similaires au mod√®le cible
   - Entra√Æn√©s sur des donn√©es publiques
   
2. **G√©n√©ration des donn√©es d'attaque**
   - Pr√©dictions sur donn√©es "in" vs "out"
   - √âtiquettes de membership
   
3. **Entra√Ænement des mod√®les d'attaque**
   - Un mod√®le par classe
   - Classification binaire : membre/non-membre

## üêõ D√©pannage

### Probl√®mes courants
1. **Erreur de m√©moire GPU** : R√©duire `BATCH_SIZE` dans `config.py`
2. **Temps d'ex√©cution long** : Utiliser l'exp√©rience rapide
3. **Mod√®les manquants** : V√©rifier le dossier `models/`

### Logs de d√©bogage
Consultez les fichiers dans `logs/` pour des informations d√©taill√©es sur les erreurs.

## üìö R√©f√©rences

1. Shokri, R., et al. "Membership inference attacks against machine learning models." 2017 IEEE Symposium on Security and Privacy.

2. McMahan, B., et al. "Communication-efficient learning of deep networks from decentralized data." AISTATS 2017.

3. Fredrikson, M., et al. "Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing." USENIX Security 2014.

## üìÑ Licence

Ce projet est √† des fins √©ducatives et de recherche. Veuillez citer les travaux originaux lors de l'utilisation.

## ü§ù Contribution

Les contributions sont les bienvenues ! Veuillez cr√©er une issue ou une pull request pour :
- Corrections de bugs
- Nouvelles fonctionnalit√©s
- Am√©liorations de la documentation
- Optimisations de performance

## üìß Contact

Pour toute question ou suggestion, n'h√©sitez pas √† ouvrir une issue sur le projet.